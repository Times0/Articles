---
category:
  - "[[Journal de bord]]"
date: 2024-12-02
---

# Notre aventure au Hackathon Digital Justice

J'ai particip√© √† mon premier hackathon d'envergure la semaine derni√®re. Organis√© par le Conseil de l'Europe √† Bologne, l'√©v√©nement r√©unissait 7 √©quipes en comp√©tition pour gagner 3 000 ‚Ç¨.

Voici l'histoire de comment on a tent√© de cr√©er en 48 heures un outil qui aurait du prendre des mois de d√©veloppement, comment on s'est retrouv√© dans une impasse technique, et comment une solution de derni√®re minute nous a permis de d√©crocher la troisi√®me place.

# Avant le Hackathon

## Comprendre le probl√®me juridique

D'abord, un peu de contexte.
Le sujet du hackathon √©tait de cr√©er un outil permettant aux professionnels du droit (avocats, juges) de trouver rapidement des jugements pertinents pour leurs affaires en cours.

√Ä ce stade, nous n'avions aucune id√©e de la complexit√© du domaine juridique. Par exemple, les lois de l'Union europ√©enne sont appliqu√©es diff√©remment selon les pays, car elles sont interpr√©t√©es √† travers le prisme de chaque juridiction nationale.

Na√Øfs mais motiv√©s, notre premi√®re √©tape √©tait de comprendre √† quoi ressemblaient ces fameux jugements.

On tombe sur un site qui r√©pertorie pleins de compte rendus de jugements ainsi que des "pr√©cis" (des r√©sum√©s de d√©cisions) et qui semble plut√¥t moderne (https://codices.coe.int/codices/documents/welcome).

On se dit que pour faire des mod√®les d'IA on a besoin de beaucoup de ces textes, donc on d√©cide de se lancer dans l'extraction des ces derniers.

## La collecte des donn√©es : techniques de scraping

J'ai utilis√© une technique classique de scraping que tout d√©veloppeur devrait conna√Ætre tant elle est utile.

Cette API √©tait peu prot√©g√©e, donc je te conseille de passer √† la partie suivante si tu ma√Ætrises d√©j√† ces concepts. Je n'ai eu besoin d'aucune technique particuli√®rement originale pour r√©cup√©rer les donn√©es (contrairement √† quand j'ai reverse-engineered l'API SNCF pour [mon outil](https://track-my-train-times.vercel.app/) de suivi des prix).

L'approche consiste √† reproduire dans un script les requ√™tes que le frontend envoie au backend, puis d'automatiser ce processus pour r√©cup√©rer toutes les donn√©es souhait√©es.

Pour cela on ouvre la console dev sur firefox (F12) et on regarde l'onglet network quand on clique sur "plus"

![alt text](assets/ezgif-7-db7251df96.gif)

Une requ√™te GET interressante apparait √† cet URL :

`https://codices.coe.int/api/precis/tree?page=1&countryCode=ech&size=20&isFinalized=true`

Et les param√®tres de la requ√™te qu'on peut modifier :

`ECH` correspond √† "European Court of Human rights"

`size` indique le nombre de r√©sultats qu'on veut obtenir.

La r√©ponse √† cette requ√™te contient une liste de 20 Titres + Id + autres infos sur les jugements qu'on veut r√©cup√©rer. ü§ë

![alt text](assets/{9017DAB9-F2ED-4421-8AD6-736D4F6C82C5}.png)

On change `size=20` pour `size=10000` et on obtient une liste des 600 jsons qui contiennent `id` et `title`. üëç

On isole maintenant la requete qui permet de charger le texte d'un jugement √† partir de son `id`.

On clique sur un article et on examine l'onglet requ√™te.

![alt text](<assets/ezgif-1-04c55e7e98 1.gif>)

Une requete GET vers `https://codices.coe.int/api/precis/DAF7533E-BA85-44F9-432E-08DCD0B6A0AC` qui renvoit un magnifique JSON strucur√©.

Il nous reste √† assembler un simple script python pour automatiser les requ√™tes pour r√©cup√©rer le contenu √† partir de chaque `id` et hop, une bdd avec pleins de jugements dans la poche üòé

Bon dans la vraie vie les donn√©es sont souvent un peu plus compliqu√©es √† scraper notamment parce qu'on ne peut pas souvent tout extraire en changeant `size=20` par `size=10000` pour tout r√©cup√©rer d'un coup mais surtout parce que les donn√©es sont souvent prot√©g√©es par de l'authentification. Il faut alors comprendre comment l'authentification est g√©r√©e.

En pratique, cela revient souvent √† ajouter des headers √† notre requ√™te. Je ferai s√ªrement d'autres articles √† ce sujet.

## Notre approche technique : embeddings et visualisation 3D

R√©cup√©rer les donn√©es de Codices ne nous a finalement pas tant aid√©s, car les juges (notamment Amaury Fouret, expert en data science √† la Cour de cassation) nous avaient pr√©par√© un ensemble de 5 bases de donn√©es h√©t√©rog√®nes contenant des fichiers HTML, PDF, DOCX et JSON.

Notre corpus comprenait :

- 20 000 textes de jugements (entre 2 et 15 pages par texte)
- Plusieurs langues (anglais, fran√ßais, grec, russe)
- Des juridictions diff√©rentes, impliquant des structures de contenu vari√©es

Notre strat√©gie √©tait de :

1. Cr√©er des embeddings √† partir de r√©sum√©s en anglais g√©n√©r√©s par LLaMA 70B
2. Stocker ces vecteurs pour permettre des calculs de similarit√© rapides
3. Extraire 3 dimensions pertinentes de ces embeddings (d'environ 1000 dimensions)
4. Repr√©senter les jugements sur une carte interactive en 3D

![Sch√©ma de notre architecture](assets/{624DB658-8062-4E93-8F38-465AFB9F0356}.png)

Cette architecture s'apparente √† un syst√®me RAG (Retrieval-Augmented Generation), domaine tr√®s en vogue actuellement. Avec le recul, notre d√©cision d'impl√©menter ces √©tapes manuellement n'√©tait peut-√™tre pas optimale - les gagnants ont utilis√© une solution cl√© en main : [Weaviate](https://weaviate.io).

Je ne vais pas d√©tailler ce qu'on a fait puisqu'on a pas pus aller au bout de cette solution, mais [Chroma db](https://github.com/chroma-core/chroma) semble etre un bon outil pour cr√©er une vector database. On l'a fait tourner avec [LegalBert](https://huggingface.co/nlpaueb/legal-bert-base-uncased) en tant qu'embedder et on obtient des r√©sultats tr√®s prometteurs sur notre base de fichiers test avec 600 fichiers.

On lui donne une phrase en input, il cr√©√© un embedding et cherche ceux qui sont les plus proches dans l'espace √† 1000 dimensions.

```python
results = collection.query(query_texts=["Tax fraud committed by foreigners"], n_results=2,)
for i in range(len(results)):
    print(results[i].id, results[i].score)
    print(results[i].embedding)
    print(results[i].metadata)

    # On peut aussi r√©cup√©rer les textes correspondants
    print(collection.get(results[i].id))
```

L'indexage a pris une vingtaine de minutes pour ces 600 fichiers,

par contre, lorsqu'on le fait tourner sur une bdd plus grosse de 20 000 ou m√™me 5000 fichiers, impossible de terminer la cr√©ation du vecteur store üòñ.

Ce fut notre plus grosse d√©ception de ce hackathon, avec ce vecteur store fonctionnel on aurait pu, j'en suis s√ªr scorer beaucoup plus au tests technique parce que oui, ce filou d'Amaury a voulu tester rigoureusement les performances de nos impl√©mentations de RAG.

Et les tests qu'il avait pr√©par√©s n'√©taient pas de tout repos ü•µ

# Le test technique

Le jury nous a transmis 60 r√©sum√©s en anglais, chacun correspondant √† un texte issu des bases de donn√©es mentionn√©es dans l'√©nonc√©.

- Les r√©sum√© avaient 3 niveaux de d√©tails (quelques phrases √† 3 pages)

- Les r√©sum√©s sont tous en anglais bien que les textes pouvaient √™tre dans d'autres langues

Il nous fallait renvoyer pour chaque r√©sum√© une liste des 100 textes les plus similaires ids+scores de confiance renvoy√©s par notre outil. üò±

Une heure avant la deadline nous n'avons litt√©ralement aucun moyen de passer une quelconque partie de ce test notre recherche de similarit√© gr√¢ce aux embeddings ayant √©chou√©. Mais nous savions qu'√©chouer ce test nous disqualifie de la comp√©tition, il fallait qu'on trouve une solution.

Et c'est l√† que les mots des mentors nous sont revenus : "vous savez, les embeddings c'est r√©cent que √ßa fonctionne, vous devriez essayer des solutions plus anciennes, √ßa marche aussi tr√®s bien."

Et hop, ni une ni deux je vais chercher un TP qu'on a fait avec Gabriel Frey deux mois auparavant sur ElasticSearch √† Telecom Strasbourg.

Un notebook compl√®tement rempli qui d√©crit tout le processus d'impl√©mentation d'Elastic Search pour une bdd de fichiers JSON.

Magnifique, gr√¢ce √† cette solution qu'on parvient √† faire fonctionner 5 min avant la deadline et avec quelques filouteries d'un membre de l'√©quipe : Ayoub on passe quelques tests avec des bons score de confiance.

On est sauv√©s, pas de disqualification !

# Frontend : map 3d + prompt

La partie vraiment originale de notre projet, c'est la visualisation de nos donn√©es sur une map 3D. Il nous fallait les choquer.

On voulait repr√©senter des cas sur une map donc on a fait une map en 3D.
Le site est host sur Vercel et dispo [Ici](https://map-my-justice.vercel.app/)

![alt text](assets/ezgif-6-dbd656204b.gif)

L'impl√©mentation de la visualisation est faite avec three JS (une biblioth√®que pour faire de la 3d avec React, tr√®s puissante)

Les jurys ont √©t√© assez partag√©s sur cette visualisation car ce n'est pas le genre de chose auxquelles on est habitu√© quand on travaille dans ce domaine je les comprenais, j'aurais du encore plus insister sur la vision que j'avais pendant la pr√©sentation pour qu'ils comprennent que cette d√©mo qu'on a fait en deux jours (et 10 prompts) √©tait loin d'√™tre la version finale que j'avais en t√™te.

J'avais pas mal d'id√©es pour am√©liorer cette visualisation sous forme de map pour la rendre plus styl√©e comme par exemple

- Zoomer directement sur le groupe de cas les plus similaires apr√®s le prompt
- Afficher les cas connect√©s avec des liens au survol
- Utiliser de effets de lumi√®re pour mettre en valeur les zones denses

Je n'ai pas parl√© de comment on passe des embeddings (750 dimensions environ) √† une repr√©sentation 3D pour la Map. C'est parce qu'on a pas eu l'occasion d'explorer cet aspect plus que √ßa.
On avait quand meme une id√©e assez claire puisqu'on savait que des algorithmes comme UMAP et t-SNE pouvaient √™tre utilis√©s pour faire de la repr√©sentation de donn√©es √† haute dimension.

Les autres teams avaient des pr√©sentations vraiment impressionnantes pour la plupart et des gens habitu√©s √† parler en public (on √©tait la seule team avec que des gens qui font de l'info). Cependant ont √©tait les seuls √† avoir propos√© quelque chose de plus qu'un simple moteur de recherche am√©lior√©. On avait la partie visualisation ce qui nous a redonn√© espoir.

Finalement ce qui a sembl√© avoir beaucoup compt√© c'est les performances aux tests techniques, car certaines √©quipes qui ont fait une magnifique pr√©sentation et dont l'outil semblait marcher extr√™mement bien n'ont pas fini dans le classement. On a appris plus tard que leur performances √©taient en fait tr√®s mauvaises et que leur d√©mo √©tait faite avec des fausses donn√©es (comme nous au final sauf qu'on a model qui marche au moins un peu).

Au final on repart avec une troisi√®me place ü•âet l'estomac bien rempli de p√¢tes √† la Bolognaise üçù.

La ville de Bologne est vraiment magnifique

Faites des hackathons c'est sympa

## Ce que nous avons appris

Ce hackathon nous a appris plusieurs le√ßons importantes :

1. **Parfois, les solutions simples sont les meilleures** - Notre sauvetage de derni√®re minute avec ElasticSearch nous a rappel√© que les technologies √©prouv√©es peuvent √™tre plus fiables que les approches de pointe dans un contexte de contrainte temporelle.

2. **L'innovation visuelle peut faire la diff√©rence** - Notre visualisation 3D nous a d√©marqu√©s des autres √©quipes qui proposaient principalement des moteurs de recherche am√©lior√©s.

3. **Les performances techniques comptent** - Certaines √©quipes avec d'excellentes pr√©sentations n'ont pas √©t√© class√©es en raison de mauvaises performances aux tests techniques.

Au final, nous repartons avec une troisi√®me place ü•â et l'estomac bien rempli de p√¢tes √† la Bolognaise üçù.

Bologne est une ville magnifique, et je ne peux que vous encourager √† participer √† des hackathons.

Les hackathons c'est cool :)

Bisous

![Bologne](assets/Pasted%20image%2020241204040003.png)
